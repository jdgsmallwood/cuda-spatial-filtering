{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dpkt\n",
    "import struct\n",
    "import typing\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def get_udp_payload_bytes(pcap_filename) -> typing.List[bytes]:\n",
    "    \"\"\"\n",
    "    Read UDP payload bytes from a .pcap(ng) file\n",
    "    return list with one entry per packet, entry containing udp payload\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    try:\n",
    "        with open(pcap_filename, \"rb\") as f:\n",
    "            pcap_read = dpkt.pcap.UniversalReader(f)\n",
    "            udp_payloads = list()\n",
    "            for ts, buf in pcap_read:\n",
    "                # skip packet if not long enough to contain IP+UDP+CODIF hdrs\n",
    "                if len(buf) < (34 + 8 + 64):\n",
    "                    print(f\"WARNING: Found packet that is too small {len(buf)}Bytes\")\n",
    "                    continue\n",
    "                eth = dpkt.ethernet.Ethernet(buf)\n",
    "                ip = eth.data\n",
    "                # skip non-UDP packets\n",
    "                if ip.p != dpkt.ip.IP_PROTO_UDP:\n",
    "                    print(f\"WARNING: Found packet that is not UDP {ip.p} type\")\n",
    "                    continue\n",
    "                # add the UDP payload data into the list of payloads\n",
    "                udp = ip.data\n",
    "                udp_payloads.append(udp.data)\n",
    "                timestamps.append(ts)\n",
    "    except FileNotFoundError as fnf_err:\n",
    "        print(fnf_err)\n",
    "        sys.exit(1)\n",
    "\n",
    "    return timestamps, udp_payloads\n",
    "\n",
    "\n",
    "N_POL = 2\n",
    "N_VALS_PER_CPLX = 2\n",
    "N_BYES_PER_VAL = 1\n",
    "N_BYTES_PER_SAMPLE = N_POL * N_VALS_PER_CPLX * N_BYES_PER_VAL\n",
    "\n",
    "\n",
    "def get_channel_power(beam, payload):\n",
    "    seq_no = struct.unpack(\"Q\", payload[0:8])[0]\n",
    "    scale1 = struct.unpack(\"f\", payload[32:36])[0]\n",
    "    first_chan = struct.unpack(\"I\", payload[48:52])[0]\n",
    "    num_chan = struct.unpack(\"H\", payload[52:54])[0]\n",
    "    valid_chan = struct.unpack(\"H\", payload[54:56])[0]\n",
    "    num_sample = struct.unpack(\"H\", payload[56:58])[0]\n",
    "    beam_id = struct.unpack(\"H\", payload[58:60])[0]\n",
    "    sample_per_weight = struct.unpack(\"B\", payload[67:68])[0]\n",
    "    if beam_id != beam:\n",
    "        return None\n",
    "    weights_offset = 96  # start of weights (multiple of 16bytes=128 bits)\n",
    "    n_weight_bytes = num_sample / sample_per_weight * 2 * num_chan\n",
    "    # weights padded to multiple of 128 bits = 16 bytes\n",
    "    data_offset = weights_offset + math.ceil(n_weight_bytes / 16) * 16\n",
    "\n",
    "    np_chanl_pwr = np.zeros((2, num_chan))\n",
    "    for ch in range(0, valid_chan):\n",
    "        ch_offset = data_offset + (\n",
    "            ch * num_sample * N_BYES_PER_VAL * N_VALS_PER_CPLX * N_POL\n",
    "        )\n",
    "        # sum sample power for both polarisations\n",
    "        for pol in range(0, 2):\n",
    "            pol_base = ch_offset + pol * num_sample * N_BYES_PER_VAL * N_VALS_PER_CPLX\n",
    "            for sample_idx in range(0, num_sample):\n",
    "                loc_x = pol_base + sample_idx * 2\n",
    "                x_i, x_q = struct.unpack(\"bb\", payload[loc_x : loc_x + 2])\n",
    "                sample_pwr = x_i * x_i + x_q * x_q\n",
    "                np_chanl_pwr[pol][ch] += sample_pwr\n",
    "    # average power per-complex-sample per channel\n",
    "    np_chanl_pwr = np_chanl_pwr / (scale1 * scale1) / valid_chan / num_sample\n",
    "    # print(f\"scale: {scale1}\")\n",
    "    # print(f\"weights_bytes: {n_weight_bytes} data_offset: {data_offset} + {valid_chan*pol*num_sample}samples\")\n",
    "    # print(f\"pol_base {pol_base}+{num_sample*2}\")\n",
    "\n",
    "    return (seq_no, first_chan, np_chanl_pwr)\n",
    "\n",
    "\n",
    "def get_packet_data(payload):\n",
    "    seq_no = struct.unpack(\"Q\", payload[0:8])[0]\n",
    "    sample_no = struct.unpack(\"Q\", payload[8:16])[0]\n",
    "    scale1 = struct.unpack(\"f\", payload[32:36])[0]\n",
    "    first_chan = struct.unpack(\"I\", payload[48:52])[0]\n",
    "    num_chan = struct.unpack(\"H\", payload[52:54])[0]\n",
    "    valid_chan = struct.unpack(\"H\", payload[54:56])[0]\n",
    "    num_sample = struct.unpack(\"H\", payload[56:58])[0]\n",
    "    beam_id = struct.unpack(\"H\", payload[58:60])[0]\n",
    "    sample_per_weight = struct.unpack(\"B\", payload[67:68])[0]\n",
    "\n",
    "    weights_offset = 96  # start of weights (multiple of 16bytes=128 bits)\n",
    "    n_weight_bytes = num_sample / sample_per_weight * 2 * num_chan\n",
    "    # weights padded to multiple of 128 bits = 16 bytes\n",
    "    data_offset = weights_offset + math.ceil(n_weight_bytes / 16) * 16\n",
    "    # samples for one packet = (channels) x (2 pol) x (time samples)\n",
    "    samples = np.zeros((valid_chan, 2, num_sample), dtype=np.complex64)\n",
    "\n",
    "    for ch in range(0, valid_chan):\n",
    "        ch_offset = data_offset + (\n",
    "            ch * num_sample * N_BYES_PER_VAL * N_VALS_PER_CPLX * N_POL\n",
    "        )\n",
    "        for pol in range(0, 2):\n",
    "            pol_base = ch_offset + pol * num_sample * N_BYES_PER_VAL * N_VALS_PER_CPLX\n",
    "            for sample_idx in range(0, num_sample):\n",
    "                loc_x = pol_base + sample_idx * 2\n",
    "                x_i, x_q = struct.unpack(\"bb\", payload[loc_x : loc_x + 2])\n",
    "                samples[ch, pol, sample_idx] = 1j * np.float32(x_q) + np.float32(x_i)\n",
    "    return (seq_no, sample_no, beam_id, first_chan, scale1, samples)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lambda_file = \"cap_13Dec2024_0.pcapng\"\n",
    "total_ADCs = 20\n",
    "pcount_max = 900\n",
    "\n",
    "# read pcap file\n",
    "tstamps, payloads = get_udp_payload_bytes(lambda_file)\n",
    "\n",
    "# run through the data to find the number of beams and channels\n",
    "first_pkt = True\n",
    "start_seq_no = 0\n",
    "start_chan = 0\n",
    "end_seq_no = 0\n",
    "end_chan = 0\n",
    "total_packets = 0\n",
    "\n",
    "for ts, pkt_payload in zip(tstamps, payloads):\n",
    "    seq_no = struct.unpack(\"<Q\", pkt_payload[0:8])[0]\n",
    "    FPGA_id = struct.unpack(\"<I\", pkt_payload[8:12])[0]\n",
    "    freq_chan = struct.unpack(\"<H\", pkt_payload[12:14])[0]\n",
    "    total_packets += 1\n",
    "    if first_pkt:\n",
    "        first_pkt = False\n",
    "        start_seq_no = seq_no\n",
    "        end_seq_no = seq_no\n",
    "        start_chan = freq_chan\n",
    "        end_chan = freq_chan\n",
    "    else:\n",
    "        if freq_chan < start_chan:\n",
    "            start_chan = freq_chan\n",
    "        if seq_no < start_seq_no:\n",
    "            start_seq_no = seq_no\n",
    "        if freq_chan > end_chan:\n",
    "            end_chan = freq_chan\n",
    "        if seq_no > end_seq_no:\n",
    "            end_seq_no = seq_no\n",
    "\n",
    "print(f\"Found {total_packets} packets\")\n",
    "print(\n",
    "    f\"Start time sample = {start_seq_no}, total time samples = {end_seq_no - start_seq_no + 1}, (= total time {1080e-9 * (end_seq_no - start_seq_no + 1)} seconds)\"\n",
    ")\n",
    "print(\n",
    "    f\"Start channel = {start_chan}, total channels = {(end_chan - start_chan) + 1}\"\n",
    ")\n",
    "total_channels = (end_chan - start_chan) + 1\n",
    "total_time_packets = (end_seq_no - start_seq_no + 1) // 64\n",
    "expected_packets = total_channels * total_time_packets\n",
    "print(f\"expected packets = {expected_packets}\")\n",
    "\n",
    "# Get all the data into a big numpy array\n",
    "# ADCs x channels x time samples\n",
    "all_samples = np.zeros(\n",
    "    (total_ADCs, total_channels, (end_seq_no - start_seq_no + 64)),\n",
    "    dtype=np.complex64,\n",
    ")\n",
    "all_samples_scaled = np.zeros(\n",
    "    (total_ADCs, total_channels, (end_seq_no - start_seq_no + 64)),\n",
    "    dtype=np.complex64,\n",
    ")\n",
    "# scale factor for each sample, initialise with -1\n",
    "all_scales = -500 * np.ones(\n",
    "    (total_ADCs, total_channels, (end_seq_no - start_seq_no + 64)), dtype=np.float32\n",
    ")\n",
    "pkt_scale = np.zeros(total_ADCs, dtype=np.float32)\n",
    "pcount = 0\n",
    "IS_FIRST_PACKET = True\n",
    "for ts, pkt_payload in zip(tstamps, payloads):\n",
    "    pcount += 1\n",
    "    seq_no = struct.unpack(\"<Q\", pkt_payload[0:8])[0]\n",
    "    FPGA_id = struct.unpack(\"<I\", pkt_payload[8:12])[0]\n",
    "    freq_chan = struct.unpack(\"<H\", pkt_payload[12:14])[0] - start_chan\n",
    "    padding = struct.unpack(\"<Q\", pkt_payload[14:22])[0]\n",
    "\n",
    "    # Get scale factors\n",
    "    for adc in range(total_ADCs):\n",
    "        pkt_scale[adc] = np.float32(\n",
    "            struct.unpack(\"H\", pkt_payload[(22 + 2 * adc) : (24 + 2 * adc)])[0]\n",
    "        )\n",
    "    # Get data\n",
    "    data_base = 22 + total_ADCs * 2\n",
    "    for adc in range(total_ADCs):\n",
    "        for t in range(64):  # 64 time samples per packet\n",
    "            x_i, x_q = struct.unpack(\n",
    "                \">bb\",\n",
    "                pkt_payload[\n",
    "                    (data_base + t * total_ADCs * 2 + adc * 2) : (\n",
    "                        data_base + t * total_ADCs * 2 + adc * 2 + 2\n",
    "                    )\n",
    "                ],\n",
    "            )\n",
    "            all_samples[adc, freq_chan, seq_no - start_seq_no + t] = (\n",
    "             #   1j * np.float32(x_q) + np.float32(x_i)\n",
    "                1j * x_q + x_i\n",
    "            )\n",
    "            # all_samples_scaled[adc, freq_chan, seq_no - start_seq_no + t] = (\n",
    "            #     pkt_scale[adc] * (1j * np.float32(x_q) + np.float32(x_i))\n",
    "            # )\n",
    "            #all_scales[adc, freq_chan, seq_no - start_seq_no + t] = pkt_scale[adc]\n",
    "    if pcount >= pcount_max:\n",
    "        print(f\"stopping packet decoding at packet {pcount}\")\n",
    "        break\n",
    "\n",
    "all_samples = all_samples.transpose((1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Open file (read-only mode)\n",
    "with h5py.File(\"first_buffer.hdf5\", \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys:\", list(f.keys()))\n",
    "    \n",
    "    # Access a dataset\n",
    "    dataset = f[\"packet_samples\"]\n",
    "    print(\"Shape:\", dataset.shape)\n",
    "    print(\"Data type:\", dataset.dtype)\n",
    "    \n",
    "    # Load data into memory (NumPy array)\n",
    "    data = dataset[:]\n",
    "\n",
    "data = data.transpose((0,1,3,2))\n",
    "data = data['r'].astype(np.float32) + 1j * data['i'].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4][0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples[4][5][:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "    for j in range(20):\n",
    "        for k in range(16):\n",
    "            assert np.isclose(data[i][k][j], all_samples[i][j][k * 64: (k+1) * 64]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
