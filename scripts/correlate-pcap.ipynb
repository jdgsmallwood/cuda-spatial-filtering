{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dpkt\n",
    "import struct\n",
    "import typing\n",
    "import argparse\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_udp_payload_bytes(pcap_filename, packets = 900) -> typing.List[bytes]:\n",
    "    \"\"\"\n",
    "    Read UDP payload bytes from a .pcap(ng) file\n",
    "    return list with one entry per packet, entry containing udp payload\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    try:\n",
    "        with open(pcap_filename, \"rb\") as f:\n",
    "            pcap_read = dpkt.pcap.UniversalReader(f)\n",
    "            udp_payloads = list()\n",
    "            pkt_count = 0\n",
    "            for ts, buf in pcap_read:\n",
    "                # skip packet if not long enough to contain IP+UDP+CODIF hdrs\n",
    "                if len(buf) < (34 + 8 + 64):\n",
    "                    print(f\"WARNING: Found packet that is too small {len(buf)}Bytes\")\n",
    "                    continue\n",
    "                eth = dpkt.ethernet.Ethernet(buf)\n",
    "                ip = eth.data\n",
    "                # skip non-UDP packets\n",
    "                if ip.p != dpkt.ip.IP_PROTO_UDP:\n",
    "                    print(f\"WARNING: Found packet that is not UDP {ip.p} type\")\n",
    "                    continue\n",
    "                # add the UDP payload data into the list of payloads\n",
    "                udp = ip.data\n",
    "                udp_payloads.append(udp.data)\n",
    "                timestamps.append(ts)\n",
    "                pkt_count+=1\n",
    "                if pkt_count == packets:\n",
    "                    break\n",
    "    except FileNotFoundError as fnf_err:\n",
    "        print(fnf_err)\n",
    "        sys.exit(1)\n",
    "\n",
    "    return timestamps, udp_payloads\n",
    "\n",
    "\n",
    "N_POL = 2\n",
    "N_VALS_PER_CPLX = 2\n",
    "N_BYES_PER_VAL = 1\n",
    "N_BYTES_PER_SAMPLE = N_POL * N_VALS_PER_CPLX * N_BYES_PER_VAL\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(prog=\"pss packet capture analyser\")\n",
    "    parser.add_argument(\"-f\", \"--file\", required=True, help=\"File to analyse\")\n",
    "    parser.add_argument(\"-t\", \"--txt\", type=str, help=\"Title text\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "#arg_parser = parse_args()\n",
    "\n",
    "lambda_file = \"/Users/jsmallwood/Documents/projects/cuda-spatial-filtering/scripts/cap_enp134s0np0_251127_1204.pcap\"\n",
    "total_ADCs = 10\n",
    "pcount_max = 9000\n",
    "\n",
    "# read pcap file\n",
    "tstamps, payloads = get_udp_payload_bytes(lambda_file, pcount_max)\n",
    "\n",
    "# run through the data to find the number of beams and channels\n",
    "first_pkt = True\n",
    "start_seq_no = 0\n",
    "start_chan = 0\n",
    "end_seq_no = 0\n",
    "end_chan = 0\n",
    "total_packets = 0\n",
    "\n",
    "for ts, pkt_payload in zip(tstamps, payloads):\n",
    "    seq_no = struct.unpack(\"<Q\", pkt_payload[0:8])[0]\n",
    "    FPGA_id = struct.unpack(\"<I\", pkt_payload[8:12])[0]\n",
    "    freq_chan = struct.unpack(\"<H\", pkt_payload[12:14])[0]\n",
    "    total_packets += 1\n",
    "    if first_pkt:\n",
    "        first_pkt = False\n",
    "        start_seq_no = seq_no\n",
    "        end_seq_no = seq_no\n",
    "        start_chan = freq_chan\n",
    "        end_chan = freq_chan\n",
    "    else:\n",
    "        if freq_chan < start_chan:\n",
    "            start_chan = freq_chan\n",
    "        if seq_no < start_seq_no:\n",
    "            start_seq_no = seq_no\n",
    "        if freq_chan > end_chan:\n",
    "            end_chan = freq_chan\n",
    "        if seq_no > end_seq_no:\n",
    "            end_seq_no = seq_no\n",
    "    if total_packets == pcount_max:\n",
    "        break\n",
    "\n",
    "print(f\"Found {total_packets} packets\")\n",
    "print(\n",
    "    f\"Start time sample = {start_seq_no}, total time samples = {end_seq_no - start_seq_no + 1}, (= total time {1080e-9 * (end_seq_no - start_seq_no + 1)} seconds)\"\n",
    ")\n",
    "print(\n",
    "    f\"Start channel = {start_chan}, total channels = {(end_chan - start_chan) + 1}\"\n",
    ")\n",
    "total_channels = (end_chan - start_chan) + 1\n",
    "total_time_packets = (end_seq_no - start_seq_no + 1) // 64\n",
    "expected_packets = total_channels * total_time_packets\n",
    "print(f\"expected packets = {expected_packets}\")\n",
    "\n",
    "# Get all the data into a big numpy array\n",
    "# ADCs x channels x time samples\n",
    "all_samples = np.zeros(\n",
    "    (total_ADCs, total_channels, (end_seq_no - start_seq_no + 64), N_POL),\n",
    "    dtype=np.complex64,\n",
    ")\n",
    "all_samples_scaled = np.zeros(\n",
    "    (total_ADCs, total_channels, (end_seq_no - start_seq_no + 64), N_POL),\n",
    "    dtype=np.complex64,\n",
    ")\n",
    "# scale factor for each sample, initialise with -1\n",
    "all_scales = -500 * np.ones(\n",
    "    (total_ADCs, total_channels, (end_seq_no - start_seq_no + 64), N_POL), dtype=np.float32\n",
    ")\n",
    "pkt_scale = np.zeros((total_ADCs, N_POL), dtype=np.float32)\n",
    "pcount = 0\n",
    "seq_nums = defaultdict(list)\n",
    "for ts, pkt_payload in tqdm(zip(tstamps, payloads), total=expected_packets):\n",
    "    pcount += 1\n",
    "    seq_no = struct.unpack(\"<Q\", pkt_payload[0:8])[0]\n",
    "    FPGA_id = struct.unpack(\"<I\", pkt_payload[8:12])[0]\n",
    "    freq_chan = struct.unpack(\"<H\", pkt_payload[12:14])[0] - start_chan\n",
    "    seq_nums[freq_chan].append(seq_no)\n",
    "    padding = struct.unpack(\"<Q\", pkt_payload[14:22])[0]\n",
    "\n",
    "    # Get scale factors\n",
    "    for adc in range(total_ADCs):\n",
    "        for p in range(N_POL):\n",
    "            pkt_scale[adc][p] = np.float32(\n",
    "            struct.unpack(\"H\", pkt_payload[(22 + 2 * adc * N_POL + 2 * p) : (24 + 2 * adc * N_POL + 2 * p)])[0]\n",
    "        )\n",
    "    # Get data\n",
    "    data_base = 22 + total_ADCs * 2 * N_POL\n",
    "    for adc in range(total_ADCs):\n",
    "        for p in range(N_POL):\n",
    "            for t in range(64):  # 64 time samples per packet\n",
    "                x_i, x_q = struct.unpack(\n",
    "                    \"bb\",\n",
    "                    pkt_payload[\n",
    "                        (data_base + t * total_ADCs * N_POL * 2 + adc * 2 * N_POL + 2 * p) : (\n",
    "                            data_base + t * total_ADCs *N_POL * 2 + adc * 2 * N_POL + 2 * p + 2\n",
    "                        )\n",
    "                    ],\n",
    "                )\n",
    "                all_samples[adc, freq_chan, seq_no - start_seq_no + t, p] = (\n",
    "                    1j * np.float32(x_q) + np.float32(x_i)\n",
    "                )\n",
    "                all_samples_scaled[adc, freq_chan, seq_no - start_seq_no + t,p] = (\n",
    "                    pkt_scale[adc][p] * (1j * np.float32(x_q) + np.float32(x_i))\n",
    "                )\n",
    "                all_scales[adc, freq_chan, seq_no - start_seq_no + t,p] = pkt_scale[adc][p]\n",
    "    if pcount >= pcount_max:\n",
    "       print(f\"stopping packet decoding at packet {pcount}\")\n",
    "       break\n",
    "\n",
    "# plt_chan = 0\n",
    "# for adc_base in range(2):\n",
    "#     plt.figure()\n",
    "#     plt.grid(True)\n",
    "#     for adc in range(5):\n",
    "#         for p in range(N_POL):\n",
    "#             plt.subplot(5, 2, 2 * adc + p + 1)\n",
    "#             plt.plot(\n",
    "#                 np.real(all_samples_scaled[adc_base * 5 + adc, plt_chan, 0:2048,p]), \"r.-\"\n",
    "#             )\n",
    "#             plt.plot(\n",
    "#                 np.imag(all_samples_scaled[adc_base * 5 + adc, plt_chan, 0:2048,p]), \"g.-\"\n",
    "#             )\n",
    "#             plt.plot(all_scales[adc_base * 5 + adc, plt_chan, 0:512,p], \"b-\")\n",
    "#             plt.title(f\"Complex samples for adc {adc_base * 5 + adc} pol {p}, scale blue\")\n",
    "\n",
    "    \n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chan, seqs in seq_nums.items():\n",
    "    \n",
    "    for i, seq in enumerate(seqs): \n",
    "        if i == 0:\n",
    "            continue\n",
    "        if seq - seqs[i-1] != 64:\n",
    "            print(f\"Diff at chan {chan} packet {i} has sequence number {seq} when expected was {seqs[i-1] + 64}. Number of missing packets is {(seq - seqs[i-1] - 64) / 64}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def triangular_adc_pairs(N):\n",
    "    \"\"\"Return list of (i, j) index pairs for lower-triangle storage.\"\"\"\n",
    "    pairs = []\n",
    "    for i in range(N):        # row\n",
    "        for j in range(i+1):  # col\n",
    "            pairs.append((i, j))\n",
    "    return pairs\n",
    "\n",
    "def hermitian_from_lower_triangular(vec, n):\n",
    "    \"\"\"\n",
    "    vec: 1D array of length n(n+1)/2 containing the LOWER triangle row-by-row.\n",
    "    n: size of the Hermitian matrix.\n",
    "    \"\"\"\n",
    "    H = np.zeros((n, n), dtype=complex)\n",
    "\n",
    "    # Fill lower triangle\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1):\n",
    "            H[i, j] = vec[idx]\n",
    "            idx += 1\n",
    "\n",
    "    # Copy lower to upper (conjugate)\n",
    "    H = H + np.tril(H, -1).conj().T\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = np.zeros(\n",
    "    (total_channels, int(total_ADCs * (total_ADCs + 1 ) /2), N_POL, N_POL),\n",
    "    dtype=np.complex64,\n",
    ")\n",
    "pairs = triangular_adc_pairs(total_ADCs)\n",
    "\n",
    "for f in range(total_channels): \n",
    "    S = all_samples_scaled[:, f, :, :]   # shape: (ADCs, time, pol)\n",
    "\n",
    "    for t_idx, (i, j) in enumerate(pairs):\n",
    "        # S[i] = shape (time, pol)\n",
    "        # Outer-product over polarization:\n",
    "        #\n",
    "        #    Corr[p,q] = sum_t S[i,t,p] * conj(S[j,t,q])\n",
    "        #\n",
    "        corr_mat[f, t_idx] = S[i].conj().T @ S[j] \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat[0, :6, 0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cap_2tone_20251119.np\", all_samples_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_scaled[0,0,:,0] @ all_samples_scaled[0,0,:,1].conj().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 0\n",
    "receiver = 9\n",
    "pol = 1\n",
    "plt.plot(all_samples_scaled[receiver,channel,:500000,pol].real)\n",
    "plt.plot(all_samples_scaled[receiver,channel,:500000,pol].imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(4-18j )* (4 + 18j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(10, 6))  # 2 rows, 4 columns\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axes[row, col].plot(\n",
    "        np.fft.fftshift(\n",
    "            np.abs(\n",
    "                np.fft.fft(all_samples_scaled[0, i, :, 0])\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    axes[row, col].set_title(f\"i = {i}\")\n",
    "    axes[row, col].set_xticks([])\n",
    "    axes[row, col].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((all_samples[:,:,:,:].real).flatten(), bins=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
